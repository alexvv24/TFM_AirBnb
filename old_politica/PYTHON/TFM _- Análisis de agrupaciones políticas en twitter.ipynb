{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis de sentimiento y agrupaci√≥nes pol√≠ticas en twitter\n",
    "Lo primero que tenemos que hacer es extraer tweets desde la api que nos ofrece twitter, tenemos el curso de datacamp disponible [aqu√≠](https://www.datacamp.com/courses/importing-data-in-python-part-2), *nos interesan los cap√≠tulos 2 y 3 especialmemte*\n",
    "Voy a ir dejando un resumen de lo que contienen para hacerlo m√°s f√°cil:\n",
    "* El formato standard, aunque no el √∫nico, que nos devuelve una api es **JSON** (JavaScript Code Notation)\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQvI8lv3nmpUyybBdhcEjtq4sW5_w-AgSyQQfhC-F2D4WTg3GU4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre la API de Twitter, que es la que nos interesa tenemos la documentaci√≥n [aqu√¨](https://developer.twitter.com/en/docs.html)\n",
    "Una **diferencia** importante que debemos conocer de la API de Twitter respecto de otras APIs es que la de Twitter requiere que tengamos una cuenta personal para realizar los requests, no podemos realizarlas de manera an√≥nima.\n",
    "\n",
    "Una vez tenemos cuenta, accedemos al siguiente [link](https://developer.twitter.com/en/apps).\n",
    "Hacemos click en \"Create an App\" y seguimos los pasos.\n",
    "Copio la respuesta m√°s larga que ten√©is que dar:\n",
    "1. A School Project for EAE Business School\n",
    "2. We plan to analyze tweets and users to build a network of the current political framework in Spain and the connections of their members.\n",
    "3. No\n",
    "4. Using the API, we import tweets and user data to Python to show Tables and Graphs about the political representation in Twitter.\n",
    "\n",
    "Una vez rellenamos todo el formulario, nos env√≠an un correo para que confirmemos nuestra cuenta, y nos toca esperar a que nos activen la cuenta de desarrollador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la API de streaming de Twitter, podemos tener acceso al 1% de todos los tweets de la red si decidimos no filtrarlos (sample), u obtener todos los que cumplan un filtro (filter).  Para ello necesitamos el paquete de [**tweepy**](https://tweepy.readthedocs.io/en/3.7.0/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy,json\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import time\n",
    "import sys\n",
    "import networkx as nx\n",
    "\n",
    "api_key = '812CaU2hXr9vz2OUjpXWDxooM' \n",
    "api_secret_key = 'NW0uyvtLWI6g96u7ImN5iJtm5Gkzv6mnguL3WOd3jXwOY5E6Da'\n",
    "access_token = '1094207020109099008-kuGFfu8hC3RZTJVeZUjbEmMMJx73gD'\n",
    "access_token_secret = 'kIZZic5s3JM4d7uVkYAxVWe0CExfLNyeMLS5rfo7fv68l'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key,api_secret_key)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para importar el objeto SListener obtenermos el c√≥digo de [este](https://github.com/SocialDataAnalytics-Winter2018/lab04/blob/master/slistener.py) enlace de Github proporcionado por *Datacamp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SListener(StreamListener):\n",
    "    def __init__(self, api = None, fprefix = 'streamer'):\n",
    "        self.api = api or API()\n",
    "        self.counter = 0\n",
    "        self.fprefix = fprefix\n",
    "        self.output  = open('%s_%s.json' % (self.fprefix, time.strftime('%Y%m%d-%H%M%S')), 'w')\n",
    "\n",
    "\n",
    "    def on_data(self, data):\n",
    "        if  'in_reply_to_status' in data:\n",
    "            self.on_status(data)\n",
    "        elif 'delete' in data:\n",
    "            delete = json.loads(data)['delete']['status']\n",
    "            if self.on_delete(delete['id'], delete['user_id']) is False:\n",
    "                return False\n",
    "        elif 'limit' in data:\n",
    "            if self.on_limit(json.loads(data)['limit']['track']) is False:\n",
    "                return False\n",
    "        elif 'warning' in data:\n",
    "            warning = json.loads(data)['warnings']\n",
    "            print(\"WARNING: %s\" % warning['message'])\n",
    "            return\n",
    "\n",
    "\n",
    "    def on_status(self, status):\n",
    "        self.output.write(status)\n",
    "        self.counter += 1\n",
    "        if self.counter >= 20000:\n",
    "            self.output.close()\n",
    "            self.output  = open('%s_%s.json' % (self.fprefix, time.strftime('%Y%m%d-%H%M%S')), 'w')\n",
    "            self.counter = 0\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_delete(self, status_id, user_id):\n",
    "        print(\"Delete notice\")\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_limit(self, track):\n",
    "        print(\"WARNING: Limitation notice received, tweets missed: %d\" % track)\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print('Encountered error with status code:', status_code)\n",
    "        return \n",
    "\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print(\"Timeout, sleeping for 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoy es d√≠a 15 de febrero de 2019, el presidente Pedro S√°nchez ha anunciado la convocatoria de elecciones para el pr√≥ximo 28 de febrero. Filtramos los tweets para encontrar los hashtags **#EleccionesGenerales** y **#28Abril**\n",
    "\n",
    "Para obtener los datos de la API utilizaremos la *Streaming API* de twitter.  De este modo obtendremos tweets solo cuando estemos conectados a la API en tiempo real, no podemos obtener tweets del pasado.\n",
    "\n",
    "Esta nos permite obtener tweets filtrando por *palabras clave*, *nombres de usuario* o *localizaciones*.\n",
    "\n",
    "La [documentaci√≥n](https://developer.twitter.com/en/docs/tweets/filter-realtime/overview) nos indica que, en la versi√≥n standard,  podemos filtrar por hasta un m√°ximo de:\n",
    "* 400 palabras clave\n",
    "* 5000 nombres de usuario\n",
    "* 25 localizaciones.\n",
    "\n",
    "Adem√°s, debemos tener en cuenta la manera en la que queremos filtrar las palabras clave, para distinguir si queremos una frase exacta o palabras por separado.  Lo tenemos en el siguiente [link](https://developer.twitter.com/en/docs/tweets/rules-and-filtering/overview/standard-operators.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer dos tipos de an√°lisis:\n",
    "\n",
    "- An√°lisis de nodos de los usuarios: relaciones entre usuarios. Metodolog√≠a: datos en streaming (filter)\n",
    "- An√°lisis de sentimientos: tweets publicados por determinadas cuentas y con ciertos hashtags. Metodolog√≠a: datos hist√≥ricos (1 semana)\n",
    "\n",
    "Para empezar, queremos sacar datos de un determinado per√≠odo para entender el contexto de tweets pol√≠ticos y poder identificar la muestra que necesitamos para hacer el an√°lisis.\n",
    "\n",
    "- Partidos pol√≠ticos y sus representantes p√∫blicos (listas oficiales de los partidos con cuenta en twitter). Tienen que estar verificadas\n",
    "\n",
    "- Cuentas no oficiales de influencers pol√≠ticos (n√∫mero determinado de seguidores seg√∫n hashtags - creados por medios de comunicaci√≥n oficiales, trending topics sobre pol√≠tica).\n",
    "\n",
    "--\n",
    "\n",
    "1. Network analysis\n",
    "Identificar comunidades, ver relaciones entre los miembros del mismo partido y entre partidos.\n",
    "Representatividad de twitter vs poblaci√≥n general.\n",
    "\n",
    "Tendencias desde 28 febrero\n",
    "\n",
    "2. An√°lisis de sentimiento\n",
    "Identificar tweets y tendencias de opini√≥n con su evoluci√≥n a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SListener' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-497ea8742117>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Instantiate the SListener object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mlisten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSListener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Instantiate the Stream object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SListener' is not defined"
     ]
    }
   ],
   "source": [
    "#Dividimos las cuentas pol√≠ticas a seguir por partido pol√≠tico:\n",
    "PP = ['@PPopular','@pablocasado_','@TeoGarciaEgea','@ALevySoler','@JavierMaroto','@DolorsMM','@MartaGlezVzqz','@jaimedeolano',\n",
    "     '@JuanMa_Moreno','@FeijooGalicia']\n",
    "Ciudadanos = ['@CiudadanosCs','@Albert_Rivera','@InesArrimadas','@GirautaOficial','@ignacioaguado',\n",
    "              '@begonavillacis','@Tonicanto1','@lugaricano']\n",
    "Vox = ['@vox_es','@Santi_ABASCAL','@ivanedlm','@Ortega_Smith','@monasterioR','@FSerranoCastro']\n",
    "PSOE = ['@PSOE','@sanchezcastejon','@abalosmeco','@susanadiaz','@JosepBorrellF','@carmencalvo_',\n",
    "        '@meritxell_batet','@Teresaribera','@mjmonteroc','@miqueliceta','@GFVara']\n",
    "Podemos_IU_Compromis_EnMarea =['@ahorapodemos','@Pablo_Iglesias_','@VeraNoelia','@pnique','@Irene_Montero_','@ionebelarra',\n",
    "                              '@GloriaElizo','@MayoralRafa','@TeresaRodr_','@MonederoJC','@RamonEspinar',\n",
    "                               '@Julio_Rodr_','@agarzon','@monicaoltra']\n",
    "\n",
    "Todos = PP+Ciudadanos+Vox+PSOE+Podemos_IU_Compromis_EnMarea\n",
    "\n",
    "# Set up words to track\n",
    "keywords_to_track = Todos\n",
    "\n",
    "# Instantiate the SListener object \n",
    "listen = SListener(api)\n",
    "\n",
    "# Instantiate the Stream object\n",
    "stream = Stream(auth, listen)\n",
    "\n",
    "# Begin collecting data\n",
    "stream.filter(track = keywords_to_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis de sentimiento\n",
    "\n",
    "Una vez tenemos la muestra, el primer paso ser√° realizar un **an√°lisis de sentimiento** utilizando las palabras contenidas en los tweets.\n",
    "\n",
    "Este m√©todo consiste en contar las palabras con connotaci√≥n positiva y negativa en un texto, en este caso, tweet, para despu√©s ponerlas en proporci√≥n con el tweet entero.\n",
    "\n",
    "La utilidad de este m√©todo se encuentra en cuantificar la reacci√≥n que produce en redes sociales un producto, empresa, ley o lo que es del inter√©s de este trabajo: **pol√≠ticos**.\n",
    "\n",
    "Esta metodolog√≠a produce un resultado num√©rico que va desde **-1** a **+1** seg√∫n lo negativo o positivo que sea el tweet en su conjunto.\n",
    "\n",
    "La librer√≠a que vamos a utilizar, llamada *VADER* es apropiada para textos cortos, distingue may√∫sculas e incluye emojis ü§ì\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
