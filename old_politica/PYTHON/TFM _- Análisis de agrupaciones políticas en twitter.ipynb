{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimiento y agrupaciónes políticas en twitter\n",
    "Lo primero que tenemos que hacer es extraer tweets desde la api que nos ofrece twitter, tenemos el curso de datacamp disponible [aquí](https://www.datacamp.com/courses/importing-data-in-python-part-2), *nos interesan los capítulos 2 y 3 especialmemte*\n",
    "Voy a ir dejando un resumen de lo que contienen para hacerlo más fácil:\n",
    "* El formato standard, aunque no el único, que nos devuelve una api es **JSON** (JavaScript Code Notation)\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQvI8lv3nmpUyybBdhcEjtq4sW5_w-AgSyQQfhC-F2D4WTg3GU4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre la API de Twitter, que es la que nos interesa tenemos la documentación [aquì](https://developer.twitter.com/en/docs.html)\n",
    "Una **diferencia** importante que debemos conocer de la API de Twitter respecto de otras APIs es que la de Twitter requiere que tengamos una cuenta personal para realizar los requests, no podemos realizarlas de manera anónima.\n",
    "\n",
    "Una vez tenemos cuenta, accedemos al siguiente [link](https://developer.twitter.com/en/apps).\n",
    "Hacemos click en \"Create an App\" y seguimos los pasos.\n",
    "Copio la respuesta más larga que tenéis que dar:\n",
    "1. A School Project for EAE Business School\n",
    "2. We plan to analyze tweets and users to build a network of the current political framework in Spain and the connections of their members.\n",
    "3. No\n",
    "4. Using the API, we import tweets and user data to Python to show Tables and Graphs about the political representation in Twitter.\n",
    "\n",
    "Una vez rellenamos todo el formulario, nos envían un correo para que confirmemos nuestra cuenta, y nos toca esperar a que nos activen la cuenta de desarrollador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la API de streaming de Twitter, podemos tener acceso al 1% de todos los tweets de la red si decidimos no filtrarlos (sample), u obtener todos los que cumplan un filtro (filter).  Para ello necesitamos el paquete de [**tweepy**](https://tweepy.readthedocs.io/en/3.7.0/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy,json\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import time\n",
    "import sys\n",
    "import networkx as nx\n",
    "\n",
    "api_key = '812CaU2hXr9vz2OUjpXWDxooM' \n",
    "api_secret_key = 'NW0uyvtLWI6g96u7ImN5iJtm5Gkzv6mnguL3WOd3jXwOY5E6Da'\n",
    "access_token = '1094207020109099008-kuGFfu8hC3RZTJVeZUjbEmMMJx73gD'\n",
    "access_token_secret = 'kIZZic5s3JM4d7uVkYAxVWe0CExfLNyeMLS5rfo7fv68l'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key,api_secret_key)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para importar el objeto SListener obtenermos el código de [este](https://github.com/SocialDataAnalytics-Winter2018/lab04/blob/master/slistener.py) enlace de Github proporcionado por *Datacamp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SListener(StreamListener):\n",
    "    def __init__(self, api = None, fprefix = 'streamer'):\n",
    "        self.api = api or API()\n",
    "        self.counter = 0\n",
    "        self.fprefix = fprefix\n",
    "        self.output  = open('%s_%s.json' % (self.fprefix, time.strftime('%Y%m%d-%H%M%S')), 'w')\n",
    "\n",
    "\n",
    "    def on_data(self, data):\n",
    "        if  'in_reply_to_status' in data:\n",
    "            self.on_status(data)\n",
    "        elif 'delete' in data:\n",
    "            delete = json.loads(data)['delete']['status']\n",
    "            if self.on_delete(delete['id'], delete['user_id']) is False:\n",
    "                return False\n",
    "        elif 'limit' in data:\n",
    "            if self.on_limit(json.loads(data)['limit']['track']) is False:\n",
    "                return False\n",
    "        elif 'warning' in data:\n",
    "            warning = json.loads(data)['warnings']\n",
    "            print(\"WARNING: %s\" % warning['message'])\n",
    "            return\n",
    "\n",
    "\n",
    "    def on_status(self, status):\n",
    "        self.output.write(status)\n",
    "        self.counter += 1\n",
    "        if self.counter >= 20000:\n",
    "            self.output.close()\n",
    "            self.output  = open('%s_%s.json' % (self.fprefix, time.strftime('%Y%m%d-%H%M%S')), 'w')\n",
    "            self.counter = 0\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_delete(self, status_id, user_id):\n",
    "        print(\"Delete notice\")\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_limit(self, track):\n",
    "        print(\"WARNING: Limitation notice received, tweets missed: %d\" % track)\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print('Encountered error with status code:', status_code)\n",
    "        return \n",
    "\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print(\"Timeout, sleeping for 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoy es día 15 de febrero de 2019, el presidente Pedro Sánchez ha anunciado la convocatoria de elecciones para el próximo 28 de febrero. Filtramos los tweets para encontrar los hashtags **#EleccionesGenerales** y **#28Abril**\n",
    "\n",
    "Para obtener los datos de la API utilizaremos la *Streaming API* de twitter.  De este modo obtendremos tweets solo cuando estemos conectados a la API en tiempo real, no podemos obtener tweets del pasado.\n",
    "\n",
    "Esta nos permite obtener tweets filtrando por *palabras clave*, *nombres de usuario* o *localizaciones*.\n",
    "\n",
    "La [documentación](https://developer.twitter.com/en/docs/tweets/filter-realtime/overview) nos indica que, en la versión standard,  podemos filtrar por hasta un máximo de:\n",
    "* 400 palabras clave\n",
    "* 5000 nombres de usuario\n",
    "* 25 localizaciones.\n",
    "\n",
    "Además, debemos tener en cuenta la manera en la que queremos filtrar las palabras clave, para distinguir si queremos una frase exacta o palabras por separado.  Lo tenemos en el siguiente [link](https://developer.twitter.com/en/docs/tweets/rules-and-filtering/overview/standard-operators.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer dos tipos de análisis:\n",
    "\n",
    "- Análisis de nodos de los usuarios: relaciones entre usuarios. Metodología: datos en streaming (filter)\n",
    "- Análisis de sentimientos: tweets publicados por determinadas cuentas y con ciertos hashtags. Metodología: datos históricos (1 semana)\n",
    "\n",
    "Para empezar, queremos sacar datos de un determinado período para entender el contexto de tweets políticos y poder identificar la muestra que necesitamos para hacer el análisis.\n",
    "\n",
    "- Partidos políticos y sus representantes públicos (listas oficiales de los partidos con cuenta en twitter). Tienen que estar verificadas\n",
    "\n",
    "- Cuentas no oficiales de influencers políticos (número determinado de seguidores según hashtags - creados por medios de comunicación oficiales, trending topics sobre política).\n",
    "\n",
    "--\n",
    "\n",
    "1. Network analysis\n",
    "Identificar comunidades, ver relaciones entre los miembros del mismo partido y entre partidos.\n",
    "Representatividad de twitter vs población general.\n",
    "\n",
    "Tendencias desde 28 febrero\n",
    "\n",
    "2. Análisis de sentimiento\n",
    "Identificar tweets y tendencias de opinión con su evolución a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SListener' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-497ea8742117>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Instantiate the SListener object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mlisten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSListener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Instantiate the Stream object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SListener' is not defined"
     ]
    }
   ],
   "source": [
    "#Dividimos las cuentas políticas a seguir por partido político:\n",
    "PP = ['@PPopular','@pablocasado_','@TeoGarciaEgea','@ALevySoler','@JavierMaroto','@DolorsMM','@MartaGlezVzqz','@jaimedeolano',\n",
    "     '@JuanMa_Moreno','@FeijooGalicia']\n",
    "Ciudadanos = ['@CiudadanosCs','@Albert_Rivera','@InesArrimadas','@GirautaOficial','@ignacioaguado',\n",
    "              '@begonavillacis','@Tonicanto1','@lugaricano']\n",
    "Vox = ['@vox_es','@Santi_ABASCAL','@ivanedlm','@Ortega_Smith','@monasterioR','@FSerranoCastro']\n",
    "PSOE = ['@PSOE','@sanchezcastejon','@abalosmeco','@susanadiaz','@JosepBorrellF','@carmencalvo_',\n",
    "        '@meritxell_batet','@Teresaribera','@mjmonteroc','@miqueliceta','@GFVara']\n",
    "Podemos_IU_Compromis_EnMarea =['@ahorapodemos','@Pablo_Iglesias_','@VeraNoelia','@pnique','@Irene_Montero_','@ionebelarra',\n",
    "                              '@GloriaElizo','@MayoralRafa','@TeresaRodr_','@MonederoJC','@RamonEspinar',\n",
    "                               '@Julio_Rodr_','@agarzon','@monicaoltra']\n",
    "\n",
    "Todos = PP+Ciudadanos+Vox+PSOE+Podemos_IU_Compromis_EnMarea\n",
    "\n",
    "# Set up words to track\n",
    "keywords_to_track = Todos\n",
    "\n",
    "# Instantiate the SListener object \n",
    "listen = SListener(api)\n",
    "\n",
    "# Instantiate the Stream object\n",
    "stream = Stream(auth, listen)\n",
    "\n",
    "# Begin collecting data\n",
    "stream.filter(track = keywords_to_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimiento\n",
    "\n",
    "Una vez tenemos la muestra, el primer paso será realizar un **análisis de sentimiento** utilizando las palabras contenidas en los tweets.\n",
    "\n",
    "Este método consiste en contar las palabras con connotación positiva y negativa en un texto, en este caso, tweet, para después ponerlas en proporción con el tweet entero.\n",
    "\n",
    "La utilidad de este método se encuentra en cuantificar la reacción que produce en redes sociales un producto, empresa, ley o lo que es del interés de este trabajo: **políticos**.\n",
    "\n",
    "Esta metodología produce un resultado numérico que va desde **-1** a **+1** según lo negativo o positivo que sea el tweet en su conjunto.\n",
    "\n",
    "La librería que vamos a utilizar, llamada *VADER* es apropiada para textos cortos, distingue mayúsculas e incluye emojis 🤓\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
